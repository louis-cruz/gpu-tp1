{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP OpenMP - October 2022\n",
    "## Part 1 : Pi\n",
    "### Compilation\n",
    "\n",
    "Louis Crouz\n",
    "Thomas Di Bianca\n",
    "\n",
    "Nos conclusions sont en partie basée sur les courbes de Cyril GOmes et Benoit Algourdin, l'exécution des tests mettant plus de 30 minutes pour la moitié des calculs en connexion à distance pour la partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -o tp_openmp_part_11_critical tp_openmp_part_11_critical.cpp -fopenmp -O3 -march=native\n",
    "!g++ -o tp_openmp_part_12_atomic tp_openmp_part_12_atomic.cpp -fopenmp -O3 -march=native\n",
    "!g++ -o tp_openmp_part_13_reduction tp_openmp_part_13_reduction.cpp -fopenmp -O3 -march=native\n",
    "!g++ -o tp_openmp_part_14_array tp_openmp_part_14_array.cpp -fopenmp -O3 -march=native"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation des performance en fonction du nombre de steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    os.remove(\"stats_pi.csv\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "num_steps = [1000000, 100000000, 10000000000]#, 1000000000000]\n",
    "nb_core = [1, 2, 4, 8]\n",
    "repeats = range(0,10)\n",
    "\n",
    "for nrepeats in repeats:\n",
    "    for nsteps in num_steps:\n",
    "        for ncore in nb_core:\n",
    "\n",
    "            args = (\"./tp_openmp_part_11_critical\", \"-C\", str(ncore), \"-N\", str(nsteps))\n",
    "            popen = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "            popen.wait()\n",
    "\n",
    "            args = (\"./tp_openmp_part_12_atomic\", \"-C\", str(ncore), \"-N\", str(nsteps))\n",
    "            popen = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "            popen.wait()\n",
    "\n",
    "            args = (\"./tp_openmp_part_13_reduction\", \"-C\", str(ncore), \"-N\", str(nsteps))\n",
    "            popen = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "            popen.wait()\n",
    "\n",
    "            args = (\"./tp_openmp_part_14_array\", \"-C\", str(ncore), \"-N\", str(nsteps))\n",
    "            popen = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "            popen.wait()\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage graphique des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('result_log.csv',header=None,names=['version','nbcore','num_steps','runtime'],dtype={\n",
    "                     'version': str,\n",
    "                     'nbcore': int,\n",
    "                     'num_steps' : int,\n",
    "                     'runtime' : float\n",
    "                 })\n",
    "\n",
    "color_num_steps = {1000000 : \"blue\", 100000000 : \"red\", 10000000000 : \"green\", 1000000000000 : \"black\"}\n",
    "\n",
    "for num_steps in df['num_steps']:\n",
    "\n",
    "   df_plot = df[(df['num_steps'] == int(num_steps))]\n",
    "   df_plot = df_plot[df_plot['version'] == \"atomic\"]\n",
    "    \n",
    "   mean_stats = df_plot.groupby(['num_steps','version','nbcore']).mean().reset_index()\n",
    "    \n",
    "   plt.plot(mean_stats['nbcore'], mean_stats['runtime'],linestyle=\"solid\",color=color_num_steps[num_steps])\n",
    "   plt.yscale('log')\n",
    "   plt.scatter(df_plot['nbcore'], df_plot['runtime'],color=color_num_steps[num_steps])\n",
    "    \n",
    "   df_plot = df[(df['num_steps'] == num_steps) & (df['version'] == \"reduce\")]\n",
    "   mean_stats = df_plot.groupby(['num_steps','version','nbcore']).mean().reset_index()\n",
    "    \n",
    "   plt.plot(mean_stats['nbcore'], mean_stats['runtime'],linestyle=\"dashed\",color=color_num_steps[num_steps])\n",
    "   plt.yscale('log')\n",
    "   plt.scatter(df_plot['nbcore'], df_plot['runtime'],color=color_num_steps[num_steps])\n",
    "\n",
    "   df_plot = df[(df['num_steps'] == num_steps) & (df['version'] == \"critical\")]\n",
    "   mean_stats = df_plot.groupby(['num_steps','version','nbcore']).mean().reset_index()\n",
    "    \n",
    "   plt.plot(mean_stats['nbcore'], mean_stats['runtime'],linestyle=\"dotted\",color=color_num_steps[num_steps])\n",
    "   plt.yscale('log')\n",
    "   plt.scatter(df_plot['nbcore'], df_plot['runtime'],color=color_num_steps[num_steps])\n",
    "\n",
    "   df_plot = df[(df['num_steps'] == num_steps) & (df['version'] == \"array\")]\n",
    "   mean_stats = df_plot.groupby(['num_steps','version','nbcore ']).mean().reset_index()\n",
    "    \n",
    "   plt.plot(mean_stats['nbcore'], mean_stats['runtime'],linestyle=\"dashdot\",color=color_num_steps[num_steps])\n",
    "   plt.yscale('log')\n",
    "   plt.x\n",
    "   plt.scatter(df_plot['nbcore'], df_plot['runtime'],color=color_num_steps[num_steps])\n",
    "\n",
    "plt.xlabel('nombre thread')\n",
    "plt.ylabel('runtime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "On remarque que les deux implémentations avec des reductions sont beaucoup plus performantes que celles de critical et atomic. On peut noter que l'augmentation du nombre de thread à part leur nature un impact négatif sur leur performance.\n",
    "\n",
    "On peut également voir sur les courbes que l'implémentation reduce est plus performante que celle avec plusieurs réductions ( ici appelé array) pour un nombre de coeurs faible ceci est en partie due au atomic qui est couteux en performances.\n",
    "Cependant plus le nombre de coeurs augmente plus array devient performante le coût d atomic étant compensait par la rapidité de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Matrix-Vector operation\n",
    "\n",
    "### Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -o tp_openmp_part_21_sequential tp_openmp_part_21_sequential.cpp -fopenmp -O3 -march=native\n",
    "!g++ -o tp_openmp_part_25_pragma tp_openmp_part_25_pragma.cpp -fopenmp -O3 -march=native\n",
    "!g++ -o tp_openmp_part_29_SIMD tp_openmp_part_29_SIMD.cpp -fopenmp -O3 -march=native"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation des performences\n",
    "\n",
    "avec :\n",
    "* N : 2, 4, 8, 10, 12, 14, 16\n",
    "* M : 1, 3, 7, 9, 11, 13, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    os.remove(\"stats_vector.csv\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "array_N = [2, 4, 8, 10, 12, 14, 16]\n",
    "array_M = [1, 3, 7, 9, 11, 13, 15]\n",
    "nbcore =[1, 2, 4, 8] \n",
    "\n",
    "for N in array_N:\n",
    "    M = N-1\n",
    "    for ncore in nbcore:\n",
    "\n",
    "        args = (\"./tp_openmp_part_21_sequential\", \"-N\", str(N), \"-M\", str(N), \"-C\", str(ncore))\n",
    "        popen = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "        popen.wait()\n",
    "\n",
    "        args = (\"./tp_openmp_part_25_pragma\", \"-N\", str(N), \"-M\", str(N), \"-C\", str(ncore))\n",
    "        popen = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "        popen.wait()\n",
    "\n",
    "        args = (\"./tp_openmp_part_29_SIMD\", \"-N\", str(N), \"-M\", str(N), \"-C\", str(ncore))\n",
    "        popen = subprocess.Popen(args, stdout=subprocess.PIPE)\n",
    "        popen.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage graphique des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('stats_vector.csv',header=None,names=['version','nbcore', 'N','M','nrepeat', 'runtime'],dtype={\n",
    "                     'version': str,\n",
    "                     \"nbcore\": int\n",
    "                     'N': float,\n",
    "                     'M' : float,\n",
    "                     'nrepeat' : float,\n",
    "                     'runtime' : float\n",
    "                 })\n",
    "\n",
    "color_N = {2**2 : \"blue\", 2**4 : \"red\", 2**8 : \"green\", 2**10 : \"black\", 2**12 : \"purple\", 2**14 :\"pink\", 2**16:\"orange\"}\n",
    "\n",
    "for N in df['N']:\n",
    "    df_plot = df[(df['N'] == float(N))]\n",
    "    df_plot = df_plot[df_plot['version'] == \"sequential\"]\n",
    "    \n",
    "    mean_stats = df_plot.groupby(['N','version','nbcore']).mean().reset_index()\n",
    "    \n",
    "    plt.plot(mean_stats['N'], mean_stats['runtime'],linestyle=\"solid\",color=color_N[N])\n",
    "    plt.yscale('log')\n",
    "    plt.scatter(df_plot['nbcore'], df_plot['runtime'],color=color_N[N])\n",
    "\n",
    "    df_plot = df[(df['N'] == N) & (df['version'] == \"pragma\")]\n",
    "    mean_stats = df_plot.groupby(['N','version','nbcore']).mean().reset_index()\n",
    "    \n",
    "    plt.plot(mean_stats['nbcore'], mean_stats['runtime'],linestyle=\"dashed\",color=color_N[N])\n",
    "    plt.yscale('log')\n",
    "    plt.scatter(df_plot['nbcore'], df_plot['runtime'],color=color_N[N])\n",
    "\n",
    "    df_plot = df[(df['N'] == N) & (df['version'] == \"SIMD\")]\n",
    "    mean_stats = df_plot.groupby(['N','version','nbcore']).mean().reset_index()\n",
    "    \n",
    "    plt.plot(mean_stats['nbcore'], mean_stats['runtime'],linestyle=\"dotted\",color=color_N[N])\n",
    "    plt.yscale('log')\n",
    "    plt.scatter(df_plot['nbcore'], df_plot['runtime'],color=color_N[N])\n",
    "    \n",
    "plt.xlabel('nombre thread')\n",
    "plt.ylabel('runtime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conculsion\n",
    "\n",
    "On remarque que l'implémentation séquentiel est la plus rapide peu importe le nombre de coeurs lorsque N est petit et cependant lorsque N augmente l'implémentation séquentiel devient beaucoup moins performante au profit des implémentations avec réduction. L'implémentation avec réduction devient plus performante lorsque le nombre de thread augmente cependant pour un grand N la différence entre pragma et simd est négligeable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
